# 社交媒体平台对仇恨言论的处理：责任与自由的博弈

**来源：** Knowledge@Wharton

**日期：** 2018年11月01日

**标签：** 科技

多年来社交媒体平台很少会删除仇恨言论，他们通常会接纳各种种族主义、憎恶同性恋和反犹太人的帖子和评论。不过最近围绕仇恨言论、言论自由和席卷美国的社会政治战争的争论愈演愈烈，社交媒体也被推到了风口浪尖上。

最近亚历克斯·琼斯(Alex Jones)掀起了一场轩然大波。长期以来这位阴谋论者一直在散布各种明显的虚假言论，比如声称知名公众人物罗伯特•米勒(Robert Mueller)、希拉里•克林顿(Hillary Clinton)运营恋童癖圈子（child-sex rings），而桑迪•胡克(Sandy Hook)枪击事件是枪支管制支持者策划的一场骗局。

八月初几大社交媒体平台终于对他忍无可忍：YouTube视频网站关闭了拥有240万订阅用户的琼斯频道，称其违反了公司关于仇恨言论的政策，苹果公司也出于同样原因从其应用程序上删除了琼斯InfoWars播客的部分内容。脸书（Facebook）也删除了琼斯的部分页面，理由是这些页面“美化暴力”，并使用“非人性化的语言来描述跨性别者、穆斯林和移民”。

推特（Twitter）动作稍慢，但最终决定“永久性地暂停”琼斯及InfoWars账号，原因是其多次违反了反虐待行为政策。

**社交媒体面临多方指责**

琼斯于是在公开渠道大肆控诉审查制度的不公。目前社交媒体公司陷入了多重困境。他们希望为用户创造一个愉悦的环境（用行业术语来说就是“安全”），同时又希望树立一个支持美国价值观、维护言论自由的形象。

社交媒体如今享受着媒体行业的主导地位，但又不希望受到监管，也不希望承担传统媒体几十年来所承载的调停真相的责任。

最重要的是，他们希望用户持续增加，这样才能保证企业利润增长。

沃顿商学院信息与决策学教授艾伦（[Gad Allon](http://knowledge.wharton.upenn.edu/faculty/gadallon/)）表示:“目前社交媒体公司发展顺风顺水，他们赚了很多钱，权力越来越大。”

近几个月来，在美国和其他国家要求屏蔽某些网络言论的呼声越来越高。前联合国高级专员侯赛因(Zeid Ra ‘ad al-Hussein)指责缅甸军方官员利用社交媒体煽动种族灭绝言论，他还呼吁脸书删除相关内容，脸书也确实这么做了。

今年早些时候，斯里兰卡政府在针对穆斯林的暴力事件后关闭了该国的脸书、WhatsApp和其他平台。直到脸书高管访问该国并承诺减少仇恨言论和社交媒体滥用，该禁令才被解除。

在多次国会听证会上，议员们纷纷要求社交媒体担负起相应责任。今年4月，脸书CEO扎克伯格在作证时被问及对仇恨言论的定义，他表示:“参议员，我认为这个问题很难回答，这是我们努力解决这个问题的原因之一。”对于让脸书删除关于否认犹太人大屠杀的页面，扎克伯格表示拒绝。

另外则有一些人认为社交媒体对内容过度控制，只向用户反馈他们已经关注过或相信的内容。宾夕法尼亚大学信息科学教授于欧（Christopher S. Yoo）表示：“令人担心的是，社交媒体正在产生一种回音室效应，这样会加剧社会的两极分化。他们可以选择传播和禁止传播哪些信息。我们的应对办法应该是从根本上限制社交媒体对信息传播的控制权。”

于欧教授补充道：“另一方面，在2017年大选之后，许多人担心社交媒体正在传递[虚假或误导性信息](http://knowledge.wharton.upenn.edu/article/what-can-curb-fake-news/)，他们的应对方法是对编辑内容加强控制。另外，剑桥分析公司([Cambridge Analytica](http://knowledge.wharton.upenn.edu/article/fallout-cambridge-analytica/))丑闻出现后，以及特朗普要求在谷歌上搜索特朗普的名字时，对搜索结果进行监管，而社交媒体不知道该如何应对。我可以理解这些企业负责人的处境，我相信他们想做正确的事，但很难确定对错的标准。”

但是，如果仇恨言论营造出一种令人恐惧和沮丧的氛围，脸书的新闻信息（news feed）是否会变成一个公众开始回避的地方呢?

**社交媒体的责任界限和法律盲点**

社交媒体可以对仇恨言论采取行动，也可以选择放之任之。目前的法律对他们的责任没有任何要求。

纽约法学院教授、《如何应对仇恨：为何说我们应该利用自由言论而不是审查制度》（_[HATE: Why We Should Resist It with Free Speech, Not Censorship](https://global.oup.com/academic/product/hate-9780190859121?cc=us&lang=en&)_）一书作者斯特尔森（Nadine Strossen）表示：“严格来说，根据第一修正案，他们可以做任何他们想做的事情。他们可以说,‘我们只会发布共和党成员的言论，’虽然受到特朗普的指责，但脸书可以做这些事。”反歧视法律可能会阻止种族歧视和其他因素的歧视，“但无法阻止政治意识形态”。

波士顿大学(Boston University)传播学教授卡罗尔(John Carroll)说道，第一修正案只涉及政府对言论自由的控制。他表示社交媒体“一直非常不愿意删除琼斯发布的虚假内容……但是作为一家私营企业，他们绝对有权这么做。”

事实上，许多美国人认为社交媒体在审查制度中扮演着积极的角色。在皮尤研究中心(Pew Research Center) [6月份针对4594名受访美国成年人进行的](http://www.pewinternet.org/2018/06/28/public-attitudes-toward-technology-companies/)调查中，当被问及是否认为社交媒体会积极审查政治观点时，72%的受访者表示赞同。共和党人尤其倾向于认同。

社交媒体公司一如既往地否认自己积极审查政治观点，而远离审查的倾向在其企业结构中根深蒂固。《美国1996年电信法》第230条规定，对于“交互式计算机服务”提供者或用户(相对于出版商)，以及传播第三方内容的提供者和用户，应免于承担责任。换句话说该法案坚定地把后来出现的社交媒体变成了一个基本上无需承担调停职责的公告板。

斯特尔森说道：“因此社交媒体在一开始就声称，‘我们不是媒体公司，我们是科技公司。’他们深知自己有权利和能力像传统媒体那样，可以选择发布什么、不发布什么，可以编辑内容，但他们故意说，‘我们选择不参与这种内容歧视，我们让所有人都拥有发声的平等权利。’”

为了避免扮演信息把关人的角色，社交媒体对自己做了这样一个定位：就像电话公司一样，只负责传达信息，对于通过其电话线路进行的对话内容没什么责任。

这个类比不合理的地方在于，打电话的人并不会听见数以千计的白人至上主义者关于否认大屠杀的言论。

于欧教授提到，第230条还规定“为正直之人屏蔽淫秽、污秽、骚扰或令人反感的内容，为创造一个安全的港湾，公司作为信息传递者拥有一定的内容编辑自由裁量权，且无需承担任何责任，如此才能平衡这些问题。”

然而对于他们应该行使多少控制权的问题，法院并没有给出明确的答案。于欧教授指出：“如果我们认真对待这项法规，社交媒体的控制仅限于淫秽或骚扰内容。不过已经有法院判决将这种责任扩大到非常广泛的类别，这将给予社交媒体公司控制其新闻源的自由。还有一些法院对责任范围的解释比较狭窄，在这种情况下，公司将面临大量责任，因此这方面存在很大的法律不确定性。”

**谁来解释言论是否正当？**

接下来是一些关于谁来解释的棘手问题；个体解释者在实践中会夹杂个人生活体验，形成偏见；在该环境下更大的问题是无法考虑算法。

例如在7月4日之前的几天里，德克萨斯州的一家社区报纸发布了《独立宣言》，但却被脸书标记为敏感内容，并删除了27至31段的内容。目前尚不清楚删除是否纯粹是算法上的问题，还是涉及到人工审查，但[据Slate报道](https://slate.com/technology/2018/07/facebook-found-hate-speech-in-the-declaration-of-independence.html)，触发因素似乎是《独立宣言》涉及“残忍的印第安野蛮人”。

沃顿商学院营销学教授伯曼([Ron Berman](http://knowledge.wharton.upenn.edu/faculty/ronber/))表示，言论监管的另一个棘手方面是，某个群体认为自由合法的言论可能被另一个群体认为是具有煽动性的，而用户协议基本上起不到什么作用。“这些协议中有很多都介于平台上不正当行为和不合理后果之间的灰色界线，这就很成问题。例如在脸书上呼吁加泰罗尼亚从西班牙独立，可能会被一大群加泰罗尼亚人视为自由合法的言论，但如果后来引发暴力抗议，则可能会被视为非法。”

社交媒体面临着越来越大的压力，要求他们对仇恨言论采取行动，但斯特尔森认为，即使琼斯蔑视、侮辱和贬低人格的思想确实违反了社交媒体社区标准，对言论进行规范将是一个严重的错误。

她补充道：“对于该概念，有两批人的看法是完全对立的。有人认为Black Lives Matter（黑人的命也是命）是对其他人的贬低。又有人说All Lives Matter（生命皆可贵）是种族主义，因为对那些生命处于危险之中的人麻木不仁。这些都是主观意见。唯一的解决办法就是不要压制言论自由。如果授权政府官员或私营部门来做自由裁定，则会造成更大的伤害。”

但社交媒体网站确实有合理的商业理由来尽可能多地消除仇恨言论。伯曼说道，像脸书这样的两面派平台面临的风险是，“如果脸书的广告定位算法允许广告商暗示基于种族、性别或其他因素的歧视，或针对性算法有可能传播仇恨言论，那么会有其他广告商不愿意出现在纵容该等广告内容的平台上。”

脸书的社区标准声明称，该平台不允许散布仇恨言论，“因为它制造了一种恐吓和排斥的环境，在某些情况下可能会助长现实世界的暴力。我们对仇恨言论的定义是基于我们所称的受保护特征对人们进行的直接攻击。我们还为外来移民身份提供了一些保护。我们将攻击（attack）定义为暴力或非人性化的言论、关于种族劣等的陈述，或要求驱逐或隔离。”

脸书、YouTube视频网站和推特正在招聘数千名新版主，或者脸书所称的“动态消息完整性数据专家”（News Feed integrity data specialists），负责对违反其标准的内容进行过滤。但据调查报道中心(Center for Investigative Reporting) [去年的一份报告](https://www.revealnews.org/article/how-activists-of-color-lose-battles-against-facebooks-moderator-army/)显示，这些版主的行为并不一致，这种不一致性让社交媒体的少数用户处于劣势。该报告援引脸书用户的例子称，他们发布的关于种族问题的帖子被脸书删除，但当他们要求白人朋友发布同样的内容时，发现这些帖子没有被删除。

斯特尔森说道：“这些标准不可避免地具有主观性，所以该等标准将按照实施者的主观价值来执行。”

然而在硅谷的思维模式中，普遍存在一种信念，即一切都可以通过算法来解决，艾伦说道：“硅谷的人认为，每一个社会问题都会找到技术解决方案。他们相信一定有解决方案，只是目前还没有找到而已。”

**自由市场的智慧**

看待该局面的另一种方式是，社交媒体作为一个行业其发展尚且不成熟。于欧教授说道：“在某种程度上，我认为社交媒体公司正在经历一场高科技的成长过程。许多技术诞生之初都会有一个善意忽视的阶段，他们没有花太多时间考虑产品的广泛社会影响以及受到监管的可能性。”

斯特尔森认为，由于社交媒体的出现，虽然有很多消极因素被释放，但很多好的事情也被广泛传播。“你通过这些新技术接触到更多的仇恨言论，同时应对仇恨言论的方法也会更加有效。如果没有社交媒体，你不可能掀起诸如Black Lives Matter、#MeToo以及反枪支运动之类的社会正义活动。多亏了社交媒体，这些运动才得以蓬勃发展。”

艾伦表示，社交媒体公司的运作方式需要更加透明：“这些算法是如何工作的?”他们是如何决定我看到什么，不看到什么? ”

另一个显而易见的解决方案是用不同的平台来适应不同的口味，有的平台用于分享假期照片、联系高中朋友，而其他平台则是侧重于政治和争议性问题。

于欧教授说道：“我认为事实上已经在这样发展。观察一下年轻人在做什么。他们同时活跃于多个社交媒体平台，对他们来说不同的平台有不同的用途。你已经开始看到社交媒体的多样化，这是一个良好的健康发展。”

乔治华盛顿大学媒体与公共事务学院副院长卡普弗(David Karpf)，与波士顿大学的卡罗尔教授共同做客沃顿知识在线，在节目中他表示，同样重要的是要注意到脸书、推特和谷歌结合在一起“基本上垄断”了数字信息环境。“如果这三家公司联手关闭你的账户，那么你的频道要想吸引大量观众就变得异常困难。”

截至6月30日，脸书的月活跃用户数为22.3亿。考虑到目前全球社交媒体用户总数为33亿，这就出现了一个问题：脸书目前的规模是不是过于庞大，很难被视为一个普通的社交媒体企业？鉴于其规模和普遍性，是否更像一个公共事业？

于欧教授则表示：“我不这么认为。人们在担心脸书的主导地位时，是否已经忘了10年前它还不存在。从更大范围内来看，新平台不断涌现或旧平台以戏剧性的方式进行改革，这表明市场动态千变万化……谷歌仅是一家20年历史的公司。苹果公司在改革之前一直处于低迷状态。这些都是令人难以置信的巨大变化，这是一个不断受到创造性破坏积极影响的行业。

![](https://www.knowledgeatwharton.com.cn/wp-content/uploads/2018/11/facebook-social-media-hate-speech-618x338.jpg)
