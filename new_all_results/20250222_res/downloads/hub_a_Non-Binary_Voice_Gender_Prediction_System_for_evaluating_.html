<!DOCTYPE html>
<html><head>
    <meta data-n-head="ssr" charset="utf-8"><meta data-n-head="ssr" data-hid="viewport" name="viewport" content="width=device-width,minimum-scale=1.0,maximum-scale=1.0,user-scalable=no"><meta data-n-head="ssr" data-hid="google-site-verification" name="google-site-verification" content="u-JiwxGIuE3RbhXnquXdzK_ik29oSJ6GTAcZ5axu0vo"><meta data-n-head="ssr" data-hid="baidu-site-verification" name="baidu-site-verification" content="code-zPrPvzUuOe"><meta data-n-head="ssr" data-hid="bytedance-verification-code" name="bytedance-verification-code" content="BD/+PKoa0lO7XlbxphuC"><meta data-n-head="ssr" data-hid="sogou_site_verification" name="sogou_site_verification" content="N0ymPtfCiv"><meta data-n-head="ssr" charset="utf-8"><meta data-n-head="ssr" data-hid="keywords" name="keywords" content="eess.AS,人机交互,机器学习,人工智能论文,AI论文"><meta data-n-head="ssr" data-hid="description" name="description" content="本文介绍了一种软件，可以使用连续的声音女性化百分比（VFP）来描述声音。该系统旨在为跨性别者在声音转换过程中和支持他们的语音治疗师使用。记录了41位法国的顺性别和跨性别者的语料库。通过感知评估，57名参与者估计了每个声音的VFP。在外部性别..."><meta data-n-head="ssr" property="og:type" content="article"><meta data-n-head="ssr" property="og:url" content="https://hub.baai.ac.cn/paper/bf2378b5-d704-47d5-ac1a-0ba12e1532ee"><meta data-n-head="ssr" property="og:release_date" content="2024-04-23T16:15:39.000Z"><meta data-n-head="ssr" property="og:title" content="Voice Passing : a Non-Binary Voice Gender Prediction System for
  evaluating Transgender voice transition - 智源社区论文"><meta data-n-head="ssr" property="og:image" content="https://simg.baai.ac.cn/papers/converted_page_1cab1c39f95e8a0ef53164aa0ce12c56-01.jpg"><meta data-n-head="ssr" data-hid="og:description" property="og:description" content="本文介绍了一种软件，可以使用连续的声音女性化百分比（VFP）来描述声音。该系统旨在为跨性别者在声音转换过程中和支持他们的语音治疗师使用。记录了41位法国的顺性别和跨性别者的语料库。通过感知评估，57名参与者估计了每个声音的VFP。在外部性别..."><title>Voice Passing : a Non-Binary Voice Gender Prediction System for
  evaluating Transgender voice transition - 智源社区论文</title><link data-n-head="ssr" rel="icon" type="image/x-icon" href="https://hub.baai.ac.cn/_nuxt/favicon.ico"><link data-n-head="ssr" rel="canonical" href="https://hub.baai.ac.cn/paper/bf2378b5-d704-47d5-ac1a-0ba12e1532ee"><script src="https://lf1-cdn-tos.bytegoofy.com/goofy/ttzz/push.js?f535aca2ecf6e8bf04036eda052c20c1daa12a4be726b2189869054cbb59189dfd9a9dcb5ced4d7780eb6f3bbd089073c2a6d54440560d63862bbf4ec01bba3a" id="ttzz"></script><script src="https://zz.bdstatic.com/linksubmit/push.js"></script><script data-n-head="ssr" src="https://hub.baai.ac.cn/shim-js/hub-modal.js"></script><script data-n-head="ssr" src="https://hm.baidu.com/hm.js?22af78906280d40a7c5ad981171db6d3"></script><script data-n-head="ssr" src="https://ticket-assets.baai.ac.cn/uploads/775529c69d2d5632895cc05e924780bb.js?ver=1.0.0"></script><script data-n-head="ssr" src="https://hub.baai.ac.cn/shim-js/last_page/lastVisitedPage.js?ver=1.0.0"></script><script data-n-head="ssr" src="https://hub-cache.baai.ac.cn/hub-prod-assets/20240731/guidance_profile_prod.js"></script><link rel="preload" href="/_nuxt/4958ceb.js" as="script"><link rel="preload" href="/_nuxt/0d2ac48.js" as="script"><link rel="preload" href="/_nuxt/css/cd3064e.css" as="style"><link rel="preload" href="/_nuxt/5f8baf5.js" as="script"><link rel="preload" href="/_nuxt/css/5ea8b9b.css" as="style"><link rel="preload" href="/_nuxt/24a67d3.js" as="script"><link rel="preload" href="/_nuxt/css/471a00d.css" as="style"><link rel="preload" href="/_nuxt/f8265b2.js" as="script"><link rel="preload" href="/_nuxt/css/595652f.css" as="style"><link rel="preload" href="/_nuxt/a6a2399.js" as="script"><link rel="stylesheet" href="/_nuxt/css/cd3064e.css"><link rel="stylesheet" href="/_nuxt/css/5ea8b9b.css"><link rel="stylesheet" href="/_nuxt/css/471a00d.css"><link rel="stylesheet" href="/_nuxt/css/595652f.css">
  </head>
  <body>
    <div id="__nuxt"><div id="__layout"><div id="app" class="app" style="opacity: 1;"><header class="header"><section class="container"><div class="logo" data-v-e393dee4=""><div class="hover-popover hover-popover--logo" style="height:60px;" data-v-2820603b="" data-v-e393dee4=""><div class="hover-popover_wrapper" data-v-2820603b=""><a href="/papers" class="logo-img" data-v-2820603b="" data-v-e393dee4=""><img src="/_nuxt/img/logo.a2943de.svg" data-v-2820603b="" data-v-e393dee4=""> <span class="light" data-v-2820603b="" data-v-e393dee4=""></span></a></div> <div class="zhezhao-popover bottom-start transition" data-v-2820603b="" style="--top: 60px; --width: 1180px;"><div class="zhezhao-popover-mask" data-v-2820603b=""></div> <div class="zhezhao-popover-content" data-v-2820603b=""><div class="iframe iframe-front-page" data-v-e393dee4="" data-v-2820603b=""><iframe src="https://hub.baai.ac.cn/frontpage/" class="iframe-main"></iframe></div></div></div></div></div> <nav class="nav" data-v-38dc0cdb=""><span data-v-38dc0cdb=""><a href="/events" target="" class="nav-item" data-v-38dc0cdb=""><i class="icon iconimage icon-activity" style="background-image:url(/_nuxt/img/activity.510a855.svg);" data-v-38dc0cdb=""></i> <span data-v-38dc0cdb="">活动</span> <!----></a></span><span data-v-38dc0cdb=""><a href="/papers" target="" class="nav-item nav-item__active" data-v-38dc0cdb=""><i class="icon iconimage icon-paper" style="background-image:url(/_nuxt/img/paper.57acc81.svg);" data-v-38dc0cdb=""></i> <span data-v-38dc0cdb="">论文</span> <!----></a></span><span data-v-38dc0cdb=""><a href="/rankings" target="" class="nav-item" data-v-38dc0cdb=""><i class="icon iconimage icon-persons" style="background-image:url(/_nuxt/img/persons.bfd4be5.svg);" data-v-38dc0cdb=""></i> <span data-v-38dc0cdb="">风云人物</span> <i class="icon nav-suffix icon-nav_top iconimage" style="background-image:url(/_nuxt/img/nav_top.64391c5.svg);" data-v-38dc0cdb=""></i></a></span><span data-v-38dc0cdb=""><a href="/" target="" class="nav-item" data-v-38dc0cdb=""><i class="icon iconimage icon-zhuanlan" style="background-image:url(/_nuxt/img/zhuanlan.7cec52f.svg);" data-v-38dc0cdb=""></i> <span data-v-38dc0cdb="">专栏</span> <!----></a></span> <span data-v-38dc0cdb=""><div role="tooltip" id="el-popover-7494" aria-hidden="true" class="el-popover el-popper navs-more-popover" tabindex="0" style="display: none;"><!----> <div data-v-38dc0cdb="" class="navs-more"><ul data-v-7c982773="" data-v-38dc0cdb="" class="popover-list"><li data-v-7c982773="" class="popover-list-item"><a data-v-7c982773="" href="/projects" target=""><i data-v-7c982773="" class="icon iconimage icon-project" style="background-image: url(&quot;/_nuxt/img/project.7e171b3.svg&quot;);"></i> <span data-v-7c982773="" class="text">项目</span></a></li><li data-v-7c982773="" class="popover-list-item"><a data-v-7c982773="" href="https://baai.org/l/linklocal" target="_blank"><i data-v-7c982773="" class="icon iconimage icon-lion_black" style="background-image: url(&quot;/_nuxt/img/lion_black.558e15a.svg&quot;);"></i> <span data-v-7c982773="" class="text">社交</span></a></li></ul></div></div><span class="el-popover__reference-wrapper"><div data-v-38dc0cdb="" class="navs-more__reference el-popover__reference" aria-describedby="el-popover-7494" tabindex="0"><i data-v-38dc0cdb="" class="icon icon-nav_more iconimage" style="width: 25px; height: 25px; background-image: url(&quot;/_nuxt/img/nav_more.1b5e8e8.svg&quot;);"></i></div></span></span></nav> <a href="https://baai.org/l/deepm" target="_blank" style="margin: 0 16px 0 10px; font-size: 0;"><img src="https://hub-cache.baai.ac.cn/hub-banner/baai-banner.png" style="height: 34px;"></a> <div id="header-search" class="header-search"><div class="header-search-main"><!----> <form action="javascript:return true" class="header-search-form" style="display:;"><label class="header-search-input"><input type="search" maxlength="100" placeholder="AI日报" value=""> <i class="icon icon-search iconfont"></i></label></form> <span class="header-search-cancel" style="display:none;">取消</span></div> <div class="van-overlay header-search-overlay" style="animation-duration:0s;display:none;"></div></div> <div class="header-right"><div class="header-btns"><button class="van-button van-button--primary van-button--small"><div class="van-button__content"><span class="van-button__text">登录/注册</span></div></button></div></div></section> <!----></header> <main class="main"><div class="paper-page" data-v-f304b99c=""><div class="main-container" data-v-f304b99c=""><div class="main-container_body" data-v-f304b99c=""><ul class="paper-page-catalog" data-v-f304b99c=""><li class="paper-page-catalog-item paper-btn-filter paper-btn-filter__actived" data-v-f304b99c=""><a href="/paper/bf2378b5-d704-47d5-ac1a-0ba12e1532ee#introduction" data-v-f304b99c="" class=""><div data-v-f304b99c="">简介</div></a></li><li class="paper-page-catalog-item paper-btn-filter" data-v-f304b99c=""><a href="/paper/bf2378b5-d704-47d5-ac1a-0ba12e1532ee#charts" data-v-f304b99c="" class=""><div data-v-f304b99c="">图表</div></a></li><li class="paper-page-catalog-item paper-btn-filter" data-v-f304b99c=""><a href="/paper/bf2378b5-d704-47d5-ac1a-0ba12e1532ee#problem_solved" data-v-f304b99c="" class=""><div data-v-f304b99c="">解决问题</div></a></li><li class="paper-page-catalog-item paper-btn-filter" data-v-f304b99c=""><a href="/paper/bf2378b5-d704-47d5-ac1a-0ba12e1532ee#key_ideas" data-v-f304b99c="" class=""><div data-v-f304b99c="">关键思路</div></a></li><li class="paper-page-catalog-item paper-btn-filter" data-v-f304b99c=""><a href="/paper/bf2378b5-d704-47d5-ac1a-0ba12e1532ee#other_highlights" data-v-f304b99c="" class=""><div data-v-f304b99c="">其它亮点</div></a></li><li class="paper-page-catalog-item paper-btn-filter" data-v-f304b99c=""><a href="/paper/bf2378b5-d704-47d5-ac1a-0ba12e1532ee#related_research" data-v-f304b99c="" class=""><div data-v-f304b99c="">相关研究</div></a></li></ul> <div class="paper-page-main" data-v-f304b99c=""><div class="paper-page-header" data-v-f304b99c=""><div class="meta-box" data-v-f304b99c=""><div class="meta-box-left" data-v-f304b99c=""><h1 id="post-title" data-v-f304b99c=""><span data-v-f304b99c="">Voice Passing : a Non-Binary Voice Gender Prediction System for
  evaluating Transgender voice transition</span> <!----></h1> <div class="paper-item-authors" data-v-4af6dfbc="" data-v-f304b99c=""><div class="paper-item-authors-container is-collapsed" data-v-4af6dfbc=""><div class="paper-item-author-info" data-v-4af6dfbc=""><div class="paper-author-info-container" data-v-fe7e236a="" data-v-4af6dfbc=""><!----> <div class="paper-author-main" data-v-fe7e236a=""><span class="paper-author-name" data-v-fe7e236a="">David Doukhan</span> <!----> <span data-v-fe7e236a="">,</span></div></div></div><div class="paper-item-author-info" data-v-4af6dfbc=""><div class="paper-author-info-container" data-v-fe7e236a="" data-v-4af6dfbc=""><!----> <div class="paper-author-main" data-v-fe7e236a=""><span class="paper-author-name" data-v-fe7e236a="">Simon Devauchelle</span> <!----> <span data-v-fe7e236a="">,</span></div></div></div><div class="paper-item-author-info" data-v-4af6dfbc=""><div class="paper-author-info-container" data-v-fe7e236a="" data-v-4af6dfbc=""><!----> <div class="paper-author-main" data-v-fe7e236a=""><span class="paper-author-name" data-v-fe7e236a="">Lucile Girard-Monneron</span> <!----> <span data-v-fe7e236a="">,</span></div></div></div><div class="paper-item-author-info" data-v-4af6dfbc=""><div class="paper-author-info-container" data-v-fe7e236a="" data-v-4af6dfbc=""><!----> <div class="paper-author-main" data-v-fe7e236a=""><span class="paper-author-name" data-v-fe7e236a="">Mía Chávez Ruz</span> <!----> <span data-v-fe7e236a="">,</span></div></div></div><div class="paper-item-author-info" data-v-4af6dfbc=""><div class="paper-author-info-container" data-v-fe7e236a="" data-v-4af6dfbc=""><!----> <div class="paper-author-main" data-v-fe7e236a=""><span class="paper-author-name" data-v-fe7e236a="">V. Chaddouk</span> <!----> <span data-v-fe7e236a="">,</span></div></div></div><div class="paper-item-author-info" data-v-4af6dfbc=""><div class="paper-author-info-container" data-v-fe7e236a="" data-v-4af6dfbc=""><!----> <div class="paper-author-main" data-v-fe7e236a=""><span class="paper-author-name" data-v-fe7e236a="">Isabelle Wagner</span> <!----> <span data-v-fe7e236a="">,</span></div></div></div><div class="paper-item-author-info" data-v-4af6dfbc=""><div class="paper-author-info-container" data-v-fe7e236a="" data-v-4af6dfbc=""><!----> <div class="paper-author-main" data-v-fe7e236a=""><span class="paper-author-name" data-v-fe7e236a="">Albert Rilliard</span> <!----> <!----></div></div></div> <!----></div> <!----> </div> <div class="article-source" data-v-f304b99c="">Proc. INTERSPEECH 2023, 5207-5211</div></div> <!----></div> <div class="meta-box" data-v-f304b99c=""><div class="paper-item-other" data-v-667b1845="" data-v-f304b99c=""><div class="paper-item-left" data-v-667b1845=""><div class="tags-wrap paper-item-tags-wrap" data-v-667b1845=""><a data-v-667b1845="" href="javascript:;" class="tag-item paper-item-tag disabled"><span data-v-667b1845="" class="tag-item_text paper-item-tag_text">eess.AS</span></a><a data-v-667b1845="" href="javascript:;" class="tag-item paper-item-tag"><span data-v-667b1845="" class="tag-item_text paper-item-tag_text">HCI</span></a><a data-v-667b1845="" href="javascript:;" class="tag-item paper-item-tag"><span data-v-667b1845="" class="tag-item_text paper-item-tag_text">ML</span></a><a data-v-667b1845="" href="javascript:;" class="tag-item paper-item-tag"><span data-v-667b1845="" class="tag-item_text paper-item-tag_text">Audio</span></a><a data-v-667b1845="" href="javascript:;" class="tag-item paper-item-tag"><span data-v-667b1845="" class="tag-item_text paper-item-tag_text">PR</span></a><a data-v-667b1845="" href="javascript:;" class="tag-item paper-item-tag"><span data-v-667b1845="" class="tag-item_text paper-item-tag_text">Data</span></a><a data-v-667b1845="" href="javascript:;" class="tag-item paper-item-tag"><span data-v-667b1845="" class="tag-item_text paper-item-tag_text">AI system</span></a></div></div> <div class="paper-item-right" data-v-667b1845=""><span class="paper-item-time" data-v-667b1845="" data-v-f304b99c="">2024年04月23日 </span></div></div> <!----></div></div> <div class="paper-page-body" data-v-f304b99c=""><div id="post-content-container" class="post-content-container" data-v-f304b99c=""><ul data-v-f304b99c=""><li class="post-content-item" data-v-f304b99c=""><div data-id="introduction" id="introduction" class="anchor post-content-title" data-v-f304b99c="">简介</div> <div class="post-content-main" data-v-f304b99c=""><div id="post-content" class="post-content" data-v-f304b99c="">本文介绍了一种软件，可以使用连续的声音女性化百分比（VFP）来描述声音。该系统旨在为跨性别者在声音转换过程中和支持他们的语音治疗师使用。记录了41位法国的顺性别和跨性别者的语料库。通过感知评估，57名参与者估计了每个声音的VFP。在外部性别平衡数据上训练了二元性别分类模型，并在重叠窗口上使用，以获得平均性别预测估计值，这些估计值被校准以预测VFP，并比基于$F_0$或声道长度的模型获得更高的准确性。训练数据的说话风格和DNN架构被证明会影响VFP的估计。模型的准确性受到说话者年龄的影响。这凸显了风格、年龄以及将性别概念视为二元或非二元的重要性，以建立足够的文化概念的统计表示。</div> <!----></div></li><li class="post-content-item" data-v-f304b99c=""><div data-id="charts" id="charts" class="anchor post-content-title" data-v-f304b99c="">图表</div> <div class="post-content-main" data-v-f304b99c=""><div class="post-charts" data-v-f304b99c=""><div data-v-2108a6f8="" data-v-f304b99c="" class="charts"><ul data-v-2108a6f8="" class="chart-preview"><li data-v-2108a6f8="" class="chart-preview-item chart-preview-item__tall chart-preview-item__wide"><div data-v-c94a4126="" data-v-2108a6f8="" class="chart-preview-item-container"><div data-v-c94a4126="" class="image" style="border-radius: 2px; transform: scale(2); width: 100%; height: 100%;"><img src="https://simg.baai.ac.cn/papers/converted_page_1cab1c39f95e8a0ef53164aa0ce12c56-01.jpg"></div></div></li></ul> </div></div></div></li><li class="post-content-item" data-v-f304b99c=""><div data-id="problem_solved" id="problem_solved" class="anchor post-content-title" data-v-f304b99c="">解决问题</div> <div class="post-content-main" data-v-f304b99c=""><div id="post-content" class="post-content" data-v-f304b99c="">本文旨在提出一种连续的声音女性化百分比（VFP）描述方法，以帮助跨性别者进行声音转换，同时为支持他们的声音治疗师提供帮助。研究的重点是如何建立一个准确的VFP预测模型。</div></div></li><li class="post-content-item" data-v-f304b99c=""><div data-id="key_ideas" id="key_ideas" class="anchor post-content-title" data-v-f304b99c="">关键思路</div> <div class="post-content-main" data-v-f304b99c=""><div id="post-content" class="post-content" data-v-f304b99c="">通过使用外部平衡性别数据训练二元性别分类模型，并在重叠窗口上使用这些模型来获得平均性别预测估计值，然后校准以预测VFP，从而提高模型的准确性。</div></div></li><li class="post-content-item" data-v-f304b99c=""><div data-id="other_highlights" id="other_highlights" class="anchor post-content-title" data-v-f304b99c="">其它亮点</div> <div class="post-content-main" data-v-f304b99c=""><div id="post-content" class="post-content" data-v-f304b99c="">本文使用了41个法语跨性别者和非跨性别者的语音语料库，并进行了感知评估。实验结果表明，训练数据的语音风格和DNN架构会影响VFP估计的准确性。此外，模型的准确性还受到说话者年龄的影响。本文的方法可以为跨性别者的声音治疗提供指导，并为研究跨性别声音转换提供新思路。</div></div></li><li class="post-content-item" data-v-f304b99c=""><div data-id="related_research" id="related_research" class="anchor post-content-title" data-v-f304b99c="">相关研究</div> <div class="post-content-main" data-v-f304b99c=""><div id="post-content" class="post-content" data-v-f304b99c="">最近的相关研究包括：1. “A Deep Learning Approach to Gender Classification of Euphonious Speech”；2. “Voice Conversion for Transgender Speakers with Non-Parallel Corpora Using Variational Autoencoder and Multi-Encoder”；3. “A Review of Voice Conversion Techniques for Non-Parallel Corpora”等。</div></div></li></ul> <!----></div> <div class="button-list action-fixed" data-v-f304b99c="" style="
            width: 1080px;
            left: 413px;
            "><!----> <div class="paper-actions-container" data-v-22c07518="" data-v-f304b99c=""><div class="paper-action" data-v-22c07518=""> <span class="paper-action-item" data-v-22c07518=""><i class="icon icon-like iconimage" style="background-image:url(/_nuxt/img/like.1ce29c7.svg);" data-v-22c07518=""></i>
      点赞
    </span> <span class="paper-action-item" data-v-22c07518=""><i class="icon icon-collect iconimage" style="background-image:url(data:image/svg+xml;base64,IDxzdmcgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2aWV3Qm94PSIwIDAgMjQgMjQiIGZpbGw9Im5vbmUiIHN0cm9rZT0iIzcxN2M5YiIgc3Ryb2tlLXdpZHRoPSIyIiBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiIGNsYXNzPSJmZWF0aGVyIGZlYXRoZXItYm9va21hcmsiPjxwYXRoIGQ9Ik0xOSAyMWwtNy01LTcgNVY1YTIgMiAwIDAgMSAyLTJoMTBhMiAyIDAgMCAxIDIgMnoiPjwvcGF0aD48L3N2Zz4=);" data-v-22c07518=""></i>
      收藏
    </span> <span class="paper-action-item" data-v-22c07518=""><i class="icon icon-reply iconimage" style="background-image:url(/_nuxt/img/reply.6bc133c.svg);" data-v-22c07518=""></i>
      评论
    </span> <span class="paper-action-item" data-v-22c07518=""><i class="icon icon-lion iconimage" style="background-image:url(/_nuxt/img/lion.9963dab.svg);" data-v-22c07518=""></i>分享到Link
    </span> </div></div></div> <div class="discuss-list" data-v-b463ecb8="" data-v-f304b99c=""><div class="van-empty van-empty__empty" data-v-b463ecb8=""><div class="van-empty__image"><i class="icon icon-lion_sofa iconimage" style="background-image:url(/_nuxt/img/lion_sofa.ea7ebcd.svg);" data-v-b463ecb8=""></i></div><p class="van-empty__description">沙发等你来抢</p><div class="van-empty__bottom">   <div class="paper-btn paper-btn-submit" data-v-b463ecb8=""><span class="text" data-v-b463ecb8="">去评论</span></div></div></div></div></div></div> <div class="clearfix" data-v-f304b99c=""></div></div> <div class="main-container_right-side" style="display:none;" data-v-f304b99c=""><div class="comment-wrapper" data-v-f304b99c=""><span class="comment-wrapper_close" data-v-f304b99c=""><i class="icon icon-close iconfont" data-v-f304b99c=""></i></span> <div class="discuss-list" data-v-491b4fea="" data-v-f304b99c=""><h3 class="discuss-list-header" data-v-491b4fea="">评论</h3> <div class="discuss-list-body" data-v-491b4fea=""><div class="reply-box reply-textarea-top" data-v-29163c5a="" data-v-491b4fea=""><div class="login-guide" data-v-29163c5a=""><div class="login-guide-text" data-v-29163c5a="">
            请先 <span style="color: #6B5CFF;" data-v-29163c5a="">登录</span> 后发表评论～
        </div></div></div> <div class="discuss-list-container" data-v-491b4fea=""><div class="van-empty van-empty__empty" data-v-491b4fea=""><div class="van-empty__image"><i class="icon icon-lion_sofa iconimage" style="background-image:url(/_nuxt/img/lion_sofa.ea7ebcd.svg);" data-v-491b4fea=""></i></div><p class="van-empty__description">沙发等你来抢</p></div></div> <!----></div></div></div></div></div> <!----></div></main> <div class="app-safe-area"></div></div></div></div><script>window.__NUXT__=(function(a,b,c,d,e,f,g,h,i){return {layout:"default",data:[{post_data:{id:f,title:g,journal:"Proc. INTERSPEECH 2023, 5207-5211",source:"https:\u002F\u002Farxiv.org\u002Fabs\u002F2404.15176v1",pdf:"https:\u002F\u002Fsimg.baai.ac.cn\u002Fpaperfile\u002Fbf2378b5-d704-47d5-ac1a-0ba12e1532ee.pdf",introduction:"本文介绍了一种软件，可以使用连续的声音女性化百分比（VFP）来描述声音。该系统旨在为跨性别者在声音转换过程中和支持他们的语音治疗师使用。记录了41位法国的顺性别和跨性别者的语料库。通过感知评估，57名参与者估计了每个声音的VFP。在外部性别平衡数据上训练了二元性别分类模型，并在重叠窗口上使用，以获得平均性别预测估计值，这些估计值被校准以预测VFP，并比基于$F_0$或声道长度的模型获得更高的准确性。训练数据的说话风格和DNN架构被证明会影响VFP的估计。模型的准确性受到说话者年龄的影响。这凸显了风格、年龄以及将性别概念视为二元或非二元的重要性，以建立足够的文化概念的统计表示。",problem_solved:"本文旨在提出一种连续的声音女性化百分比（VFP）描述方法，以帮助跨性别者进行声音转换，同时为支持他们的声音治疗师提供帮助。研究的重点是如何建立一个准确的VFP预测模型。",key_ideas:"通过使用外部平衡性别数据训练二元性别分类模型，并在重叠窗口上使用这些模型来获得平均性别预测估计值，然后校准以预测VFP，从而提高模型的准确性。",other_highlights:"本文使用了41个法语跨性别者和非跨性别者的语音语料库，并进行了感知评估。实验结果表明，训练数据的语音风格和DNN架构会影响VFP估计的准确性。此外，模型的准确性还受到说话者年龄的影响。本文的方法可以为跨性别者的声音治疗提供指导，并为研究跨性别声音转换提供新思路。",related_research:"最近的相关研究包括：1. “A Deep Learning Approach to Gender Classification of Euphonious Speech”；2. “Voice Conversion for Transgender Speakers with Non-Parallel Corpora Using Variational Autoencoder and Multi-Encoder”；3. “A Review of Voice Conversion Techniques for Non-Parallel Corpora”等。",charts:[d],authors:["David Doukhan","Simon Devauchelle","Lucile Girard-Monneron","Mía Chávez Ruz","V. Chaddouk","Isabelle Wagner","Albert Rilliard"],area:[h,"cs.HC","cs.LG","cs.SD","cs.PR","cs.Data","cs.System"],events:b,no_hub_related:b,hotness_value:c,post_id:b,release_time:i,hotness_1d:c,hotness_7d:c,hotness_30d:c,last_updated_1d:"2024-10-26T00:35:30.390Z",last_updated_7d:"2024-10-20T00:35:30.390Z",last_updated_30d:"2024-09-27T00:35:30.390Z",area_ZH:[h,"人机交互","机器学习","声音","模式识别","数据处理","AI系统"]},charts:[{url:d}],hotnessData:[],headConfig:{title:g,keywords:"eess.AS,人机交互,机器学习,人工智能论文,AI论文",id:f,created_at_edit:i,description:"本文介绍了一种软件，可以使用连续的声音女性化百分比（VFP）来描述声音。该系统旨在为跨性别者在声音转换过程中和支持他们的语音治疗师使用。记录了41位法国的顺性别和跨性别者的语料库。通过感知评估，57名参与者估计了每个声音的VFP。在外部性别...",cover_url:d}}],fetch:{},error:b,state:{fragment:{tags:[],eventTicket:b,hotWords:[]},searchForm:{searchValue:"",showSearchHistory:a,showSearchResults:a,showSearchForm:e,showCategoryMenu:a,hoverIndex:-1},system:{platform:{isTablet:a,isiPhone:a,isAndroid:a,isApp:a,isPc:e,isEdge:a,isNativeChrome:a,isSafari:a},isLogin:b,loginInfo:{},browserRouteState:{}}},serverRendered:e,routePath:"\u002Fpaper\u002Fbf2378b5-d704-47d5-ac1a-0ba12e1532ee",config:{_app:{basePath:"\u002F",assetsPath:"\u002F_nuxt\u002F",cdnURL:b}}}}(false,null,"0","https:\u002F\u002Fsimg.baai.ac.cn\u002Fpapers\u002Fconverted_page_1cab1c39f95e8a0ef53164aa0ce12c56-01.jpg",true,"bf2378b5-d704-47d5-ac1a-0ba12e1532ee","Voice Passing : a Non-Binary Voice Gender Prediction System for\n  evaluating Transgender voice transition","eess.AS","2024-04-23T16:15:39.000Z"));</script><script src="/_nuxt/4958ceb.js" defer=""></script><script src="/_nuxt/f8265b2.js" defer=""></script><script src="/_nuxt/a6a2399.js" defer=""></script><script src="/_nuxt/0d2ac48.js" defer=""></script><script src="/_nuxt/5f8baf5.js" defer=""></script><script src="/_nuxt/24a67d3.js" defer=""></script>
  

<div class="search-history" style="display: none;"><div class="search-history-container"><!----> <section class="search-history-section"><h4 class="search-history-head">搜索热词</h4> <ul class="search-history-list search-history-suggest"><li class="search-history-suggest-item"><span class="search-history-suggest-index">1</span> <a href="javascript:;" class="search-history-suggest-name">Chatgpt</a></li><li class="search-history-suggest-item"><span class="search-history-suggest-index">2</span> <a href="javascript:;" class="search-history-suggest-name">预训练模型</a></li><li class="search-history-suggest-item"><span class="search-history-suggest-index">3</span> <a href="javascript:;" class="search-history-suggest-name">多模态</a></li><li class="search-history-suggest-item"><span class="search-history-suggest-index">4</span> <a href="javascript:;" class="search-history-suggest-name">智源大会</a></li><li class="search-history-suggest-item"><span class="search-history-suggest-index">5</span> <a href="javascript:;" class="search-history-suggest-name">NLP</a></li><li class="search-history-suggest-item"><span class="search-history-suggest-index">6</span> <a href="javascript:;" class="search-history-suggest-name">知识图谱</a></li><li class="search-history-suggest-item"><span class="search-history-suggest-index">7</span> <a href="javascript:;" class="search-history-suggest-name">悟道</a></li><li class="search-history-suggest-item"><span class="search-history-suggest-index">8</span> <a href="javascript:;" class="search-history-suggest-name">OpenAI</a></li><li class="search-history-suggest-item"><span class="search-history-suggest-index">9</span> <a href="javascript:;" class="search-history-suggest-name">强化学习</a></li></ul></section></div></div><div class="search-results" style="display: none;"><div class="search-results-container"><section class="search-results-section"><!----> <div class="search-results-item">查看【】的搜索结果</div></section></div></div><!----></body></html>
